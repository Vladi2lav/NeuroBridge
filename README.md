# Техническое задание: Инклюзивная образовательная платформа (MVP)

## 1. Общее описание проекта

Разработка кроссплатформенного приложения (Web, Mobile, Desktop) на базе фреймворка Flutter. Платформа предназначена для проведения текстовых и видеоуроков с глубокой адаптацией интерфейса и функционала под пользователей с ограничениями по здоровью (Accessibility-first).

**Технологический стек:**

* **Фронтенд:** Flutter.
* **Распознавание речи (STT):** Faster-Whisper (выполнение на стороне клиента для независимости от интернета).
* **Синтез речи (TTS):** Kokoro-82M (выполнение на стороне клиента).
* **Анализ текста:** LLM на сервере для формирования JSON профиля пользователя и форматирования лекций.

## 2. Архитектура и хранение данных

* **Авторизация:** Отсутствует. Платформа полностью анонимна.
* **Идентификация:** Сервер присваивает каждому новому сеансу уникальный ID для маршрутизации внутри комнаты урока (защита от подмены ID в рамках MVP не требуется).
* **Хранение данных:** Профиль доступности (JSON) сохраняется локально (Cookies / LocalStorage). При входе с нового устройства процесс онбординга проходится заново.

## 3. Пользовательские сценарии

### Шаг 1: Онбординг и сбор базовой информации

При первом входе на платформу пользователя встречает стартовый экран.

1. Запрос ФИО пользователя.
2. Система задает вопрос (текстом и дублирует голосом через TTS): *"Есть ли у вас ограничения по здоровью?"*.
3. Ожидание ответа:
* Голосом: система слушает ключевые слова «да» или «нет» (и их синонимы, если точного совпадения нет — ИИ приводит речь к ожидаемым вариантам).
* Интерфейсом: кнопки «Да» / «Нет».


4. **Ветвление логики:**
* **Ответ «Нет»:** Отключить все ассистенты (озвучку, СДВГ-режимы, голосовое управление). Перенаправить на Главный экран. Микрофон выключается до момента, пока он не понадобится для звонка.
* **Ответ «Да»:** Переход к Шагу 2.



### Шаг 2: Оценка ограничений здоровья

1. Активация текстового поля и микрофона.
2. Пользователь описывает свои трудности (голосом или текстом).
3. Нейросеть (LLM) анализирует ввод и формирует JSON-файл со списком проблем (зрение, слух, речь, концентрация).
4. Если LLM выдает ошибку или не может сформировать валидный JSON, запрос повторяется автоматически.
5. JSON сохраняется в локальное хранилище, и пользователь перенаправляется на Главный экран.

### Шаг 3: Главный экран и Настройки доступности

На главном экране доступны три основных действия: «Настройки доступности», «Создать урок» и «Присоединиться к уроку».

* **Настройки доступности:** Меню, где можно вручную редактировать созданный нейросетью профиль ограничений, а также менять размер шрифта.
* Меню настроек всегда можно открыть и изменить голосом.
* При слепоте: интерфейс озвучивается автоматически, ожидается голосовой выбор пунктов.

## 4. Специфика адаптации под здоровье (Accessibility Features)

### Зрение

* Полная озвучка интерфейса и навигация голосом.
* Управление видеозвонком при помощи голосовых команд.

### Слух и Речь

* Генерация субтитров в реальном времени во время видеозвонков.

### Зрение + Слух (Комбинированные нарушения)

* Платформа исходит из предположения о *частичной* потере.
* При наличии обоих маркеров в JSON система автоматически устанавливает максимальную громкость TTS и максимальный размер шрифта.

### Концентрация (СДВГ)

* Автоматическое сокращение (саммаризация) больших текстовых лекций.
* Применение проверенных паттернов фокусировки: режим фокуса (затемнение остальной части экрана при чтении абзаца), смысловое разбиение на карточки или Bionic Reading.

## 5. Проведение уроков

### Создание урока

Пользователь выбирает формат: видеоурок или текстовая лекция.

* **Видеоурок:** Создателю выдается 6-значный код. Звонок не начинается до тех пор, пока к комнате по этому коду не подключится минимум один участник (всего участников может быть сколько угодно).
* **Текстовая лекция:** Создатель может напечатать текст или надиктовать его голосом.
* Диктовка идет через локальный STT (устойчиво к обрывам сети).
* ИИ автоматически считывает сказанное, исправляет ошибки распознавания и красиво форматирует текст, учитывая контекст всей лекции.
* После сохранения выдается (текстом и голосом) код подключения для слушателей. Если подключается пользователь с нарушениями зрения — лекция зачитывается ему автоматически.



### Присоединение к уроку

Пользователь вводит 6-значный код.

## 6. Обработка ошибок и краевые случаи (Error Handling)

### Блокировка микрофона

* Если для пользователя критически важен микрофон (например, полная слепота), но доступ не дан, система запрашивает его.
* В случае перманентной блокировки микрофона на уровне ОС/браузера (когда системный попап больше не вызывается), интерфейс отображает полноэкранное предупреждение с инструкцией по разблокировке микрофона в настройках, дублируя эту инструкцию голосом.

### Ошибка 6-значного кода

* Если код не найден, система показывает визуальную ошибку "Код не найден, попробуйте снова".
* Если у пользователя в JSON активны проблемы со зрением, система дополнительно озвучивает ошибку голосом и предлагает продиктовать код заново.

### Обрывы связи

* Так как STT/TTS работают на стороне клиента, процесс диктовки лекции или озвучивания интерфейса не прерывается. Отправка данных на сервер (или запрос к LLM для форматирования) ставится в очередь и выполняется при восстановлении соединения.
