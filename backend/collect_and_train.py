import cv2
import numpy as np
import os
import mediapipe as mp
from sklearn.model_selection import train_test_split

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.utils import to_categorical

mp_hands = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils

# --- –ù–ê–°–¢–†–û–ô–ö–ò ---
DATA_PATH = os.path.join(os.path.dirname(__file__), 'MP_Data')

# –¢–£–¢ –ü–ò–®–ò –°–í–û–ò –ñ–ï–°–¢–´!
actions = np.array(['–ü—Ä–∏–≤–µ—Ç', '–î–∞', '–ù–µ—Ç', '–°–ø–∞—Å–∏–±–æ', '–ü–æ–∫–∞']) 

no_sequences = 30     # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ "–¥—É–±–ª–µ–π" –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∂–µ—Å—Ç–∞
sequence_length = 30  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤ –≤ "–¥—É–±–ª–µ" (–ø—Ä–∏–º–µ—Ä–Ω–æ 1 —Å–µ–∫—É–Ω–¥–∞ –≤–∏–¥–µ–æ)

def prepare_folders():
    for action in actions:
        for sequence in range(no_sequences):
            try:
                os.makedirs(os.path.join(DATA_PATH, action, str(sequence)))
            except:
                pass

def extract_keypoints(results):
    lh = np.zeros(21*3)
    rh = np.zeros(21*3)
    if results.multi_hand_landmarks:
        for idx, hand_landmarks in enumerate(results.multi_hand_landmarks):
            handedness = results.multi_handedness[idx].classification[0].label
            res = np.array([[lm.x, lm.y, lm.z] for lm in hand_landmarks.landmark]).flatten()
            if handedness == 'Left':
                lh = res
            else:
                rh = res
    return np.concatenate([lh, rh])

def collect_data():
    prepare_folders()
    cap = cv2.VideoCapture(0)
    with mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5, max_num_hands=2) as hands:
        for action in actions:
            print(f"\n[–í–ù–ò–ú–ê–ù–ò–ï] –ü–æ–¥–≥–æ—Ç–æ–≤—å—Ç–µ—Å—å –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –∂–µ—Å—Ç: {action}")
            cv2.waitKey(2000) 
            
            for sequence in range(no_sequences):
                for frame_num in range(sequence_length):
                    ret, frame = cap.read()
                    
                    if not ret:
                        continue

                    # MediaPipe –ø—Ä–æ—Ü–µ—Å—Å
                    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    image.flags.writeable = False                  
                    results = hands.process(image)                 
                    image.flags.writeable = True                   
                    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)

                    # –†–∏—Å—É–µ–º –ø–∞–ª–æ—á–∫–∏ –∏ —Ç–æ—á–∫–∏ –Ω–∞ —Ä—É–∫–∞—Ö
                    if results.multi_hand_landmarks:
                        for hand_landmarks in results.multi_hand_landmarks:
                            mp_drawing.draw_landmarks(
                                image, 
                                hand_landmarks, 
                                mp_hands.HAND_CONNECTIONS, 
                                mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4), 
                                mp_drawing.DrawingSpec(color=(250, 44, 250), thickness=2, circle_radius=2)
                            )
                    
                    # –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –Ω–∞ —ç–∫—Ä–∞–Ω–µ
                    if frame_num == 0: 
                        cv2.putText(image, '–ù–ê–ß–ê–õ–û –ó–ê–ü–ò–°–ò', (120,200), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 3)
                        cv2.putText(image, f'{action} | –î—É–±–ª—å {sequence + 1}/{no_sequences}', (15, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)
                        cv2.imshow('–°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∂–µ—Å—Ç–æ–≤', image)
                        cv2.waitKey(1500) # –î–∞–µ–º –ø–∞—É–∑—É –ø–µ—Ä–µ–¥ —Å–∞–º–∏–º –¥—É–±–ª–µ–º —Ä—É–∫–∞–º–∏!
                    else:
                        cv2.putText(image, f'{action} | –î—É–±–ª—å {sequence + 1}/{no_sequences}', (15, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)
                        cv2.imshow('–°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∂–µ—Å—Ç–æ–≤', image)
                    
                    keypoints = extract_keypoints(results)
                    npy_path = os.path.join(DATA_PATH, action, str(sequence), str(frame_num))
                    np.save(npy_path, keypoints)

                    if cv2.waitKey(10) & 0xFF == ord('q'):
                        print("–ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º.")
                        cap.release()
                        cv2.destroyAllWindows()
                        return

        cap.release()
        cv2.destroyAllWindows()
        print("\n[+] –°–ë–û–† –î–ê–ù–ù–´–• –£–°–ü–ï–®–ù–û –û–ö–û–ù–ß–ï–ù!")

def train_model():
    print("\n--- –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è ---")
    sequences, labels = [], []
    # –°–æ–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ —Ç–æ, —á—Ç–æ —É–¥–∞–ª–æ—Å—å —É—Å–ø–µ—à–Ω–æ –æ—Ç—Å–Ω—è—Ç—å
    valid_actions = []
    
    for action in actions:
        action_has_data = False
        for sequence in range(no_sequences):
            window = []
            is_valid_sequence = True
            for frame_num in range(sequence_length):
                npy_path = os.path.join(DATA_PATH, action, str(sequence), f"{frame_num}.npy")
                if os.path.exists(npy_path):
                    res = np.load(npy_path)
                    window.append(res)
                else:
                    is_valid_sequence = False
                    break # –ï—Å–ª–∏ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –∫–∞–¥—Ä–æ–≤, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —ç—Ç–æ—Ç –¥—É–±–ª—å
                    
            if is_valid_sequence:
                sequences.append(window)
                # –ü–æ–∫–∞ —Å–∫–ª–∞–¥–∏—Ä—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ (–ù–∞–∑–≤–∞–Ω–∏—è –∂–µ—Å—Ç–æ–≤) –≤–º–µ—Å—Ç–æ –∏–Ω–¥–µ–∫—Å–æ–≤!
                labels.append(action)
                action_has_data = True
                
        if action_has_data:
            valid_actions.append(action)

    if len(sequences) == 0:
        print("\n[!] –û–®–ò–ë–ö–ê: –ù–µ—Ç –∑–∞–ø–∏—Å–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è!")
        print("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏ –ø—É–Ω–∫—Ç 1 –∏ –∑–∞–ø–∏—à–∏ –∂–µ—Å—Ç—ã –Ω–∞ –∫–∞–º–µ—Ä—É.")
        return

    # –¢–µ–ø–µ—Ä—å —Å–æ–∑–¥–∞–µ–º label_map –¢–û–õ–¨–ö–û –∏–∑ —Ç–µ—Ö –∂–µ—Å—Ç–æ–≤, –¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ
    label_map = {label:num for num, label in enumerate(valid_actions)}
    
    # –ü—Ä–µ–≤—Ä–∞—â–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –º–µ—Ç–∫–∏ –≤ —á–∏—Å–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–æ–≤–æ–π –∫–∞—Ä—Ç—ã
    numeric_labels = [label_map[label] for label in labels]

    print(f"\n–î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã. –ù–∞–π–¥–µ–Ω–æ –¥—É–±–ª–µ–π: {len(sequences)}")
    print(f"–û–±—É—á–∞–µ–º—Å—è –Ω–∞ –∂–µ—Å—Ç–∞—Ö: {valid_actions}")
    
    X = np.array(sequences)
    y = to_categorical(numeric_labels).astype(int)

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)

    print("\n--- –°–±–æ—Ä–∫–∞ LSTM –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ ---")
    model = Sequential()
    model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(sequence_length, 126)))
    model.add(LSTM(128, return_sequences=True, activation='relu'))
    model.add(LSTM(64, return_sequences=False, activation='relu'))
    model.add(Dense(64, activation='relu'))
    model.add(Dense(32, activation='relu'))
    # –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π —Ç–µ–ø–µ—Ä—å —Ä–∞–≤–µ–Ω –ö–û–õ–ò–ß–ï–°–¢–í–£ –°–û–ë–†–ê–ù–ù–´–• –∂–µ—Å—Ç–æ–≤, –∞ –Ω–µ –≤—Å–µ–º 5 –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ –∑–∞–¥–∞–Ω–Ω—ã–º!
    model.add(Dense(len(valid_actions), activation='softmax'))

    model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])

    print("\n--- –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ ---")
    model.fit(X_train, y_train, epochs=120, callbacks=[])

    model_path = os.path.join(os.path.dirname(__file__), 'gesture_model.h5')
    model.save(model_path)
    
    # –°–û–•–†–ê–ù–Ø–ï–ú –°–ü–ò–°–û–ö –ñ–ï–°–¢–û–í –î–õ–Ø –°–ï–†–í–ï–†–ê
    classes_path = os.path.join(os.path.dirname(__file__), 'gesture_classes.txt')
    with open(classes_path, 'w', encoding='utf-8') as f:
        f.write('\n'.join(valid_actions))
        
    print(f"\n[+] –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_path}")

if __name__ == '__main__':
    print("="*50)
    print("ü§ñ –ê–°–°–ò–°–¢–ï–ù–¢ –û–ë–£–ß–ï–ù–ò–Ø –ñ–ï–°–¢–û–í TENSORFLOW ü§ñ")
    print("="*50)
    print("1. –°–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –∫–∞–º–µ—Ä–æ–π (–¢—Ä–µ–±—É–µ—Ç—Å—è –≤–µ–±–∫–∞!)")
    print("2. –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
    choice = input("\n–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ (1 –∏–ª–∏ 2): ")
    if choice == '1':
        print("\n=> –ó–∞–ø—É—Å–∫ –∫–∞–º–µ—Ä—ã...")
        collect_data()
    elif choice == '2':
        train_model()
    else:
        print("–ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä.")
