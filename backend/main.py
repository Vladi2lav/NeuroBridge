import asyncio
import base64
import json
import logging
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware

import uvicorn
import cv2
import numpy as np
import mediapipe as mp
from concurrent.futures import ThreadPoolExecutor
import time
import math
import os

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
try:
    from tensorflow.keras.models import load_model
    gesture_model = load_model('gesture_model.h5')
    
    # –ß–∏—Ç–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –∫–ª–∞—Å—Å—ã, –Ω–∞ –∫–æ—Ç–æ—Ä—ã—Ö –º–æ–¥–µ–ª—å –±—ã–ª–∞ –æ–±—É—á–µ–Ω–∞
    classes_path = 'gesture_classes.txt'
    if os.path.exists(classes_path):
        with open(classes_path, 'r', encoding='utf-8') as f:
            gesture_actions = np.array([line.strip() for line in f if line.strip()])
    else:
        # –ï—Å–ª–∏ –≤–¥—Ä—É–≥ —Ñ–∞–π–ª–∞ –Ω–µ—Ç, –ø–∞–¥–∞–µ–º –Ω–∞ –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç
        gesture_actions = np.array(['–ü—Ä–∏–≤–µ—Ç'])
        print("[-] gesture_classes.txt –Ω–µ –Ω–∞–π–¥–µ–Ω! –°—É–±—Ç–∏—Ç—Ä—ã –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–µ–≤–µ—Ä–Ω—ã–º–∏.")
        
    print(f"[+] –ú–æ–¥–µ–ª—å TensorFlow –∑–∞–≥—Ä—É–∂–µ–Ω–∞! –ñ–µ—Å—Ç—ã: {gesture_actions.tolist()}")
except Exception as e:
    gesture_model = None
    gesture_actions = []
    print(f"[-] –ú–æ–¥–µ–ª—å TensorFlow –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ (—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –æ—Ç–∫–ª—é—á–µ–Ω–æ): {e}")

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)



# –î–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç—è–∂–µ–ª–æ–π –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –±–µ–∑ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ FastAPI
executor = ThreadPoolExecutor(max_workers=4)

logger = logging.getLogger("api")

@app.get("/")
def read_root():
    return {"status": "NeuroERP Backend is running", "message": "Connection OK"}

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    print("Client connected to general WS")
    try:
        while True:
            data = await websocket.receive_text()
            print(f"Received msg: {data}")
            if data == "ping":
                await websocket.send_text("pong")
            else:
                await websocket.send_text(f"Echo: {data}")
    except WebSocketDisconnect:
        print("Client disconnected from general WS")

@app.websocket("/ws/hand_tracking")
async def hand_tracking_endpoint(websocket: WebSocket):
    await websocket.accept()
    
    # 1 –í 1 –ù–ê–°–¢–†–û–ô–ö–ò –° –û–ë–£–ß–ï–ù–ò–ï–ú: 
    # –ö–∞–∂–¥—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø–æ–ª—É—á–∞–µ—Ç –°–í–û–Æ –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—É—é "–∫–∞–º–µ—Ä—É" MediaPipe
    client_hands = mp.solutions.hands.Hands(
        static_image_mode=False,
        max_num_hands=2,
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5
    )
    
    def process_image_sync(image):
        return client_hands.process(image)
    print("Client connected for Hand Tracking")

    clench_start_time = 0
    was_fist = False
    
    # LSTM –ë—É—Ñ–µ—Ä
    sequence = []
    current_subtitle = ""
    last_gesture = ""
    last_gesture_time = 0
    last_frame_time = 0 # –î–ª—è –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–π –∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏–∏ FPS

    try:
        while True:
            # –ß–∏—Ç–∞–µ–º —Å—Ä–∞–∑—É –±–∏–Ω–∞—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –±–µ–∑ –Ω–∞–∫–ª–∞–¥–Ω—ã—Ö —Ä–∞—Å—Ö–æ–¥–æ–≤ JSON –∏ Base64
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫: 1 –±–∞–π—Ç (format), 4 –±–∞–π—Ç–∞ (width), 4 –±–∞–π—Ç–∞ (height), 4 –±–∞–π—Ç–∞ (rotation) = 13 –±–∞–π—Ç –º–∏–Ω–∏–º—É–º
            data = await websocket.receive_bytes()
            # –£–ë–†–ê–ù üì• [–°–ï–†–í–ï–†] –ü–æ–ª—É—á–µ–Ω –∫–∞–¥—Ä
            
            if len(data) < 16:
                continue

            # –ü–∞—Ä—Å–∏–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ (16 –±–∞–π—Ç)
            format_code = data[0]
            w = int.from_bytes(data[1:5], byteorder='little')
            h = int.from_bytes(data[5:9], byteorder='little')
            rotation = int.from_bytes(data[9:13], byteorder='little', signed=True)
            # –£–ë–†–ê–ù üìã [–°–ï–†–í–ï–†] –ó–∞–≥–æ–ª–æ–≤–æ–∫

            img_data = data[16:]
            img = None

            try:
                if format_code == 0: # NV21
                    if w > 0 and h > 0:
                        nparr = np.frombuffer(img_data, np.uint8).reshape((h + h // 2, w))
                        img = cv2.cvtColor(nparr, cv2.COLOR_YUV2BGR_NV21)
                elif format_code == 1: # BGRA8888
                    if w > 0 and h > 0:
                        nparr = np.frombuffer(img_data, np.uint8).reshape((h, w, 4))
                        img = cv2.cvtColor(nparr, cv2.COLOR_BGRA2BGR)
                elif format_code == 2: # RGBA8888 (–ò–∑ Flutter RepaintBoundary)
                    if w > 0 and h > 0:
                        nparr = np.frombuffer(img_data, np.uint8)
                        expected_len = h * w * 4
                        if len(nparr) == expected_len:
                            nparr = nparr.reshape((h, w, 4))
                            # –°—Ä–∞–∑—É –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤–æ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç RGB, –∫–æ—Ç–æ—Ä—ã–π –Ω—É–∂–µ–Ω MediaPipe
                            img = cv2.cvtColor(nparr, cv2.COLOR_RGBA2RGB)
                        else:
                            continue
                else:
                    nparr = np.frombuffer(img_data, np.uint8)
                    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

                if img is None:
                    continue

                # Rotate image if rotation is provided (MediaPipe expects upright images)
                if rotation == 90:
                    img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)
                elif rotation == 180:
                    img = cv2.rotate(img, cv2.ROTATE_180)
                elif rotation == 270:
                    img = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)

                # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –£–ñ–ï –≤ RGB –ø–æ—Å–ª–µ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è RGBA2RGB
                img_rgb = img
                
                # –ó–µ—Ä–∫–∞–ª–∏—Ä—É–µ–º –∫–∞–¥—Ä, —á—Ç–æ–±—ã –≤–µ—Ä–Ω—É—Ç—å –µ–≥–æ –≤ –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π (–Ω–µ–∑–µ—Ä–∫–∞–ª—å–Ω—ã–π) –≤–∏–¥ –≤–µ–±-–∫–∞–º–µ—Ä—ã, 
                # –ö–ê–ö –ë–´–õ–û –ü–†–ò –û–ë–£–ß–ï–ù–ò–ò –°–ï–¢–ò! –≠—Ç–æ –ø–æ—á–∏–Ω–∏—Ç –ø—É—Ç–∞–Ω–∏—Ü—É –ª–µ–≤–æ–π/–ø—Ä–∞–≤–æ–π —Ä—É–∫–∏!
                img_rgb = cv2.flip(img_rgb, 1)
                
                # –ó–∞–ø—É—Å–∫–∞–µ–º MediaPipe –≤ –ø—É–ª–µ –ø–æ—Ç–æ–∫–æ–≤, —á—Ç–æ–±—ã –æ–Ω –ù–ï –±–ª–æ—á–∏–ª asyncio event loop!
                loop = asyncio.get_event_loop()
                results = await loop.run_in_executor(executor, process_image_sync, img_rgb)
            except Exception as e:
                # –û—Å—Ç–∞–≤–ª—è–µ–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫—É—é –æ—à–∏–±–∫—É, —á—Ç–æ–±—ã –∑–Ω–∞—Ç—å –µ—Å–ª–∏ –∫–æ–Ω–≤–µ–π–µ—Ä —É–ø–∞–ª
                print(f"üö® [–°–ï–†–í–ï–†] –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞–¥—Ä–∞ (OpenCV -> MediaPipe): {e}")
                continue

            hand_landmarks_list = []
            if results.multi_hand_landmarks:
                # print(f"‚úã [–°–ï–†–í–ï–†] –ù–∞–π–¥–µ–Ω–æ —Ä—É–∫: {len(results.multi_hand_landmarks)}") # Removed per instruction
                for idx, hand_landmarks in enumerate(results.multi_hand_landmarks):
                    landmarks = []
                    for lm in hand_landmarks.landmark:
                        landmarks.append({
                            # –ó–ï–†–ö–ê–õ–ò–†–£–ï–ú X, –ø–æ—Ç–æ–º—É —á—Ç–æ –∫–∞–º–µ—Ä–∞ –≤–æ Flutter –∑–µ—Ä–∫–∞–ª—å–Ω–∞—è.
                            # –≠—Ç–æ –≤–µ—Ä–Ω–µ—Ç –≥–µ–æ–º–µ—Ç—Ä–∏—é –≤ –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π "—Ä–µ–∞–ª—å–Ω—ã–π" –º–∏—Ä.
                            "x": 1.0 - lm.x,
                            "y": lm.y,
                            "z": lm.z
                        })
                    hand_landmarks_list.append(landmarks)
            # else:
                # print("üîç [–°–ï–†–í–ï–†] –†—É–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ —ç—Ç–æ–º –∫–∞–¥—Ä–µ.") # Removed per instruction

            # Virtual elements logic
            # (–£–¥–∞–ª–µ–Ω–æ –ø–æ –∑–∞–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è)

            # --- –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø –ù–ï–ô–†–û–°–ï–¢–ò (LSTM) ---
            lh = np.zeros(21*3)
            rh = np.zeros(21*3)
            if results.multi_hand_landmarks:
                for idx, hand_landmarks in enumerate(results.multi_hand_landmarks):
                    handedness = results.multi_handedness[idx].classification[0].label
                    # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã X –±–µ—Ä–µ–º —Å—ã—Ä—ã–º–∏, –ø–æ—Ç–æ–º—É —á—Ç–æ –º—ã –£–ñ–ï –ø–µ—Ä–µ–≤–µ—Ä–Ω—É–ª–∏ –∫–∞—Ä—Ç–∏–Ω–∫—É –≤—ã—à–µ!
                    res = np.array([[lm.x, lm.y, lm.z] for lm in hand_landmarks.landmark]).flatten()
                    if handedness == 'Left':
                        lh = res
                    else:
                        rh = res
            keypoints = np.concatenate([lh, rh])
            
            # --- –ê–î–ê–ü–¢–ò–í–ù–ê–Ø –ß–ê–°–¢–û–¢–ê –ö–ê–î–†–û–í –î–õ–Ø LSTM ---
            # –ß—Ç–æ–±—ã –º–æ–¥–µ–ª—å –Ω–µ "–∑–∞–º–µ–¥–ª—è–ª–∞—Å—å", –µ—Å–ª–∏ —Ç–µ–ª–µ—Ñ–æ–Ω –∑–∞–≤–∏—Å –∏–ª–∏ —Å–µ—Ç—å —Ç–æ—Ä–º–æ–∑–∏—Ç,
            # –∑–∞–ø–æ–ª–Ω—è–µ–º –±—É—Ñ–µ—Ä —Ç–∞–∫, –±—É–¥—Ç–æ –∫–∞–¥—Ä—ã –∏–¥—É—Ç —Ä–æ–≤–Ω–æ –≤ 30 FPS (~33ms).
            now = time.time()
            if last_frame_time == 0:
                delta_t = 0.033
            else:
                delta_t = now - last_frame_time
            last_frame_time = now
            
            frames_to_add = max(1, int(delta_t / 0.0333))
            frames_to_add = min(frames_to_add, 30) # –ú–∞–∫—Å–∏–º—É–º 30 –∫–∞–¥—Ä–æ–≤ (1 —Å–µ–∫ —Ç–∏—à–∏–Ω—ã)
            
            for _ in range(frames_to_add):
                sequence.append(keypoints)
                
            sequence = sequence[-30:] # –•—Ä–∞–Ω–∏–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 (–æ–∫–Ω–æ –≤ ~1 —Å–µ–∫)
            
            if len(sequence) == 30 and gesture_model is not None:
                # –ï—Å–ª–∏ –≤ –¢–ï–ö–£–©–ï–ú –∫–∞–¥—Ä–µ –µ—Å—Ç—å —Ä—É–∫–∏ (—á—Ç–æ–±—ã –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç—å –ø—É—Å—Ç–æ—Ç—É –ø–æ–≤–µ—Ä—Ö —Å—Ç–∞—Ä–æ–≥–æ –±—É—Ñ–µ—Ä–∞)
                if np.sum(keypoints) > 0:
                    try:
                        # –î–µ–ª–∞–µ–º –±—ã—Å—Ç—Ä—ã–π –ø—Ä–µ–¥–∏–∫—Ç –ø—Ä—è–º–æ —Ç—É—Ç. –î–ª—è –±–∞—Ç—á–∞ = 1 –æ–Ω –º–≥–Ω–æ–≤–µ–Ω–Ω—ã–π
                        res_pred = gesture_model.predict(np.expand_dims(sequence, axis=0), verbose=0)[0]
                        best_idx = np.argmax(res_pred)
                        
                        # –ï—Å–ª–∏ –Ω–µ–π—Ä–æ–Ω–∫–∞ —É–≤–µ—Ä–µ–Ω–∞ –±–æ–ª–µ–µ —á–µ–º –Ω–∞ 70% (–ø–æ–Ω–∏–∂–µ–Ω–æ –¥–ª—è –æ—Ç–∑—ã–≤—á–∏–≤–æ—Å—Ç–∏)
                        if res_pred[best_idx] > 0.70: 
                            word = str(gesture_actions[best_idx])
                            now = time.time()
                            # –ö—É–ª–¥–∞—É–Ω: —á—Ç–æ–±—ã –Ω–µ —Å–ø–∞–º–∏–ª–æ –æ–¥–Ω–æ –∏ —Ç–æ –∂–µ —Å–ª–æ–≤–æ –∫—É—á—É —Ä–∞–∑ –ø–æ–¥—Ä—è–¥,
                            # –µ—Å–ª–∏ —ç—Ç–æ —Ç–æ –∂–µ —Å–∞–º–æ–µ —Å–ª–æ–≤–æ, –∂–¥–µ–º 2 —Å–µ–∫—É–Ω–¥—ã.
                            if word == last_gesture and (now - last_gesture_time) < 2.0:
                                current_subtitle = ""
                            else:
                                current_subtitle = word
                                last_gesture = word
                                last_gesture_time = now
                        else:
                            current_subtitle = "" # –°–±—Ä–æ—Å, –µ—Å–ª–∏ –∂–µ—Å—Ç –Ω–µ–ø–æ–Ω—è—Ç–µ–Ω
                    except Exception as e:
                        pass
                else:
                    current_subtitle = "" # –°–±—Ä–æ—Å, –µ—Å–ª–∏ —Ä—É–∫ –Ω–µ—Ç –≤ –∫–∞–¥—Ä–µ

            await websocket.send_json({
                "type": "hands_data",
                "hands": hand_landmarks_list,
                "subtitle": current_subtitle
            })

    except WebSocketDisconnect:
        pass
    except Exception as e:
        print(f"üö® [–°–ï–†–í–ï–†] –ì–ª–æ–±–∞–ª—å–Ω–∞—è –æ—à–∏–±–∫–∞ –≤–µ–±—Å–æ–∫–µ—Ç–∞ Hand Tracking: {e}")
    finally:
        client_hands.close()

import uuid
from typing import Dict, Any

# In-memory dictionary to store Websocket connections for WebRTC signaling
# rooms[room_id][client_id] = WebSocket
rooms: Dict[str, Dict[str, WebSocket]] = {}

@app.websocket("/ws/signal/{room_id}")
async def signaling_endpoint(websocket: WebSocket, room_id: str):
    await websocket.accept()
    if room_id not in rooms:
        rooms[room_id] = {}
        
    client_id = str(uuid.uuid4())
    rooms[room_id][client_id] = websocket
    print(f"[WS] + User {client_id} CONNECTED to room {room_id}. Total users in room: {len(rooms[room_id])}")
    
    # Send the user their ID and the list of others
    other_peers = [pid for pid in rooms[room_id].keys() if pid != client_id]
    await websocket.send_json({"type": "room_state", "my_id": client_id, "peers": other_peers})
    
    # Notify others that this peer joined
    for pid, client_ws in list(rooms[room_id].items()):
        if pid != client_id:
            await client_ws.send_json({"type": "peer_joined", "peer_id": client_id})
    
    try:
        while True:
            data = await websocket.receive_text()
            try:
                msg = json.loads(data)
                target_id = msg.get("to")
                # Ensure the message has a "from" assigned by the server for security
                msg["from"] = client_id
                
                # Targeted sending
                if target_id and target_id in rooms[room_id]:
                    await rooms[room_id][target_id].send_text(json.dumps(msg))
                else:
                    # Generic broadcast
                    for pid, client_ws in list(rooms[room_id].items()):
                        if pid != client_id:
                            await client_ws.send_text(json.dumps(msg))
            except json.JSONDecodeError:
                pass
    except WebSocketDisconnect:
        if client_id in rooms.get(room_id, {}):
            del rooms[room_id][client_id]
        if not rooms[room_id]:
            del rooms[room_id]
        else:
            for pid, client_ws in list(rooms[room_id].items()):
                try:
                    await client_ws.send_json({"type": "peer_left", "peer_id": client_id})
                except:
                    pass
        print(f"[WS] - User {client_id} DISCONNECTED from room {room_id}. Remaining: {len(rooms.get(room_id, {}))}")
    except Exception as e:
        print(f"[WS] ! ERROR in room {room_id}: {str(e)}")
        if room_id in rooms and client_id in rooms[room_id]:
            del rooms[room_id][client_id]

import socket
import os
import shutil
from fastapi import File, UploadFile, Form, HTTPException
from fastapi.responses import FileResponse
from pydantic import BaseModel

class MaterialGenRequest(BaseModel):
    title: str
    description: str

@app.post("/api/rooms/{room_id}/materials/upload")
async def upload_material(room_id: str, file: UploadFile = File(...)):
    room_dir = os.path.join("materials", room_id)
    os.makedirs(room_dir, exist_ok=True)
    file_path = os.path.join(room_dir, file.filename)
    with open(file_path, "wb") as buffer:
        shutil.copyfileobj(file.file, buffer)
    return {"status": "success", "filename": file.filename}

@app.post("/api/rooms/{room_id}/materials/generate")
async def generate_material(room_id: str, req: MaterialGenRequest):
    room_dir = os.path.join("materials", room_id)
    os.makedirs(room_dir, exist_ok=True)
    content = f"–õ–µ–∫—Ü–∏—è: {req.title}\n\n–û–ø–∏—Å–∞–Ω–∏–µ: {req.description}\n\n–ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π –æ–±—ä–µ–º —Ç–µ–∫—Å—Ç–∞, –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—â–∏–π —Å–æ–±–æ–π –ª–µ–∫—Ü–∏–æ–Ω–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª.\n(–ù–µ–π—Ä–æ—Å–µ—Ç—å –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∑–¥–µ—Å—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã: –ª–µ–∫—Ü–∏—è —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω–∞.)"
    safe_filename = "".join([c for c in req.title if c.isalpha() or c.isdigit() or c==' ']).rstrip() or "generated"
    filename = f"{safe_filename}.txt"
    file_path = os.path.join(room_dir, filename)
    with open(file_path, "w", encoding="utf-8") as f:
        f.write(content)
    return {"status": "success", "filename": filename}

@app.get("/api/rooms/{room_id}/materials")
def list_materials(room_id: str):
    room_dir = os.path.join("materials", room_id)
    if not os.path.exists(room_dir):
        return {"materials": []}
    files = os.listdir(room_dir)
    return {"materials": files}

@app.get("/api/rooms/{room_id}/materials/{filename}")
def download_material(room_id: str, filename: str):
    file_path = os.path.join("materials", room_id, filename)
    if os.path.exists(file_path):
        return FileResponse(path=file_path, filename=filename)
    raise HTTPException(status_code=404, detail="File not found")

def get_local_ip():
    s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    try:
        # doesn't even have to be reachable
        s.connect(('10.255.255.255', 1))
        IP = s.getsockname()[0]
    except Exception:
        IP = '127.0.0.1'
    finally:
        s.close()
    return IP

@app.get("/api/rooms/available")
def get_available_room():
    i = 1
    while True:
        room_id = str(i)
        if room_id not in rooms or len(rooms[room_id]) == 0:
            return {"room_id": room_id}
        i += 1

if __name__ == "__main__":
    ip = get_local_ip()
    port = 8001
    print("\n" + "="*50)
    print("üöÄ NEURO ERP BACKEND IS STARTING üöÄ")
    print("="*50)
    print(f"‚úÖ –í–í–ï–î–ò–¢–ï –≠–¢–û–¢ –ê–î–†–ï–° –í –¢–ï–õ–ï–§–û–ù–ï: {ip}:{port}")
    print("="*50 + "\n")
    uvicorn.run("main:app", host="0.0.0.0", port=port, reload=False)
